import sys
import logging
import bisect
import collections
import math
import numpy as np
from scipy import ndimage as nd
import importlib.util

from DSH import Config as cf
from DSH import ROIcorr as rc
from DSH import MIfile as MI
from DSH import MIstack as MIs
from DSH import SharedFunctions as sf
from DSH import IOfunctions as iof

def GenerateGrid2D(shape, extent=None, center=[0, 0], angle=0, coords='cartesian', indexing='xy'):
    '''Generates a grid of pixel coordinates
    
    Parameters
    ----------
    shape:  shape of the map [num_rows, num_cols].
    extent: extent of the mapping [x_left, x_right, y_bottom, y_top], 
            in physical units. They can be reversed (e.g. x2<x1)
            If None, it will be set to [0, shape[1], shape[0], 0]
    center: center of the coordinate system, in physical units
    angle:  Eventually rotate the coordinate system by angle, in radians
            for cartesian coordinates:
            - 0 means (xt, xn)=(x, y)
            - pi/2 means (xt, xn)=(y, -x)
              (note: +y points downward if indexing='xy')
            for polar coordinates:
            - 0 means theta=0 along +x
            - pi/2 means theta=0 along +y
              (note: this means downwards if indexing='xy')
    coords: ['cartesian'|'polar'] to return [x,y] or [r,theta] respectively
    indexing: ['xy'|'ij'], numpy.meshgrid indexing method
    
    Returns
    -------
    _grid  : couple of 2D arrays with coordinates for each pixel
             (either [x, y] or [r, theta], with theta in [-pi, pi] range)
    '''
    
    # Note: matplotlib extent is [x_left, x_right, y_bottom, y_top], 
    # meshgrid extent is [x_left, x_right, y_top, y_bottom] if indexing='xy'
    if extent is None:
        x_left, x_right, y_bottom, y_top = 0, shape[1], shape[0], 0
    else:
        x_left, x_right, y_bottom, y_top = extent
    
    # Pixel coordinates in physical units
    _grid = np.meshgrid(np.linspace(x_left-center[0], x_right-center[0], shape[1]),\
                        np.linspace(y_top-center[1], y_bottom-center[1], shape[0]), indexing=indexing)
    
    if coords=='cartesian':    
        if (angle != 0):
            # Coordinatees in the rotated reference frame
            _xt, _xn = np.multiply(_grid[0], np.cos(angle)) - np.multiply(_grid[1], np.sin(angle)),\
                       np.multiply(_grid[1], np.cos(angle)) + np.multiply(_grid[0], np.sin(angle))
#            logging.debug('Cartesian grid generated with angle={0}. xt_range={1}, xn_range={2}'.format(angle, [np.min(_xt), np.max(_xt)],
#                                                                                                [np.min(_xn), np.max(_xn)]))
            return [_xt, _xn]
        else:
#            logging.debug('Cartesian grid generated with angle=0. xrange={0}, yrange={1}'.format([np.min(_grid[0]), np.max(_grid[0])],
#                                                                                                [np.min(_grid[1]), np.max(_grid[1])]))
            return _grid
    elif coords=='polar':
        _theta = np.arctan2(_grid[1], _grid[0])-angle
        if (angle != 0):
            _theta = np.mod(_theta+np.pi, 2*np.pi)-np.pi
        _r = np.linalg.norm(_grid, axis=0)
#        logging.debug('Polar grid generated with angle={0}. r_range={1}, theta_range={2}'.format(angle, [np.min(_r), np.max(_r)],
#                                                                                            [np.min(_theta), np.max(_theta)]))
        return [_r, _theta]
    else:
        raise ValueError('Unknown coordinate system ' + str(coords))

def GenerateMasks(coords, shape, center=None, common_mask=None, binary_res=False, coordsystem='polar', ref_angle=0):
    """Generate a list of regions of interest, labelled either in the form of binary images, 
    each one with 0s everywhere and 1 inside the region of interest,
    or by mask index, 0-based (in this case only one mask is returned).
    Pixels belonging to no mask will be labeled with -1
    
    Parameters
    ----------
    coords       : list of mask coordinates in the form 
                    - [r, a, dr, da], as the one generated by PolarMaskCoords(), if coordsystem=='polar'
                    - [x, y, dx, dy], if coordsystem=='cartesian'
    shape        : shape of the binary image (num_rows, num_cols)
    center       : center of polar coordinates. If None, it will be the center of the image
    common_mask  : eventually specify common mask to be multiplied to every mask
    binary_res   : if True, returns list of binary masks, otherwise label pixels by binary masks
                   Warning: no overlap is allowed at this time with this indexing scheme
    coordsystem  : {'polar', 'cartesian'} to specify the coordinate system coords live in
    ref_angle    : eventually tilt the reference frame by ref_angle (0 is positive x axis)
    
    Returns
    -------
    if binary_res: a 3D array, one page per binary images (mask)
    else: a 2D array with labels (0-based), one per binary image.
          Pixels belonging to no mask will be labeled with -1
          from this, binary masks can be generated by using np.where() 
          note: in case of overlaps, overlapping pixels will be associated to first ROI only
    """
    if (center == None):
        center = np.multiply(coords, 0.5)          
    
    px_coord_0, px_coord_1 = GenerateGrid2D(shape, center=center, angle=ref_angle, coords=coordsystem)
    if common_mask is None:
        common_mask = np.ones_like(px_coord_0, dtype=int)
        
    if binary_res:
        res = np.zeros((len(coords), shape[0], shape[1]), dtype=np.dtype('b'))
    else:
        res = np.zeros(shape, dtype=int)
    for m_idx in range(len(coords)):
        rmin, rmax, amin, amax = coords[m_idx][0]-0.5*coords[m_idx][2], coords[m_idx][0]+0.5*coords[m_idx][2], coords[m_idx][1]-0.5*coords[m_idx][3], coords[m_idx][1]+0.5*coords[m_idx][3]        
        cur_mask = np.where(np.logical_and(common_mask>0,
                                           np.logical_and(np.logical_and(px_coord_0>=rmin, px_coord_0<rmax),
                                                          np.logical_and(px_coord_1>=amin, px_coord_1<amax))),
                            1, 0)
        if False:
            cur_mask = np.multiply(common_mask, np.multiply(\
                            np.multiply(0.5 * (np.sign(np.add    (-(coords[m_idx][0]-0.5*coords[m_idx][2])+np.finfo(np.float32).eps, px_coord_0)) + 1),\
                                        0.5 * (np.sign(np.subtract((coords[m_idx][0]+0.5*coords[m_idx][2])-np.finfo(np.float32).eps, px_coord_0)) + 1)),\
                            np.multiply(0.5 * (np.sign(np.add    (-(coords[m_idx][1]-0.5*coords[m_idx][3])+np.finfo(np.float32).eps, px_coord_1)) + 1),\
                                        0.5 * (np.sign(np.subtract((coords[m_idx][1]+0.5*coords[m_idx][3])-np.finfo(np.float32).eps, px_coord_1)) + 1))).astype(int))
        if binary_res:
            res[m_idx] += cur_mask
        else:
            res += cur_mask*(m_idx+1)*np.where(res>0, 0, 1)
    
    if binary_res:
        logging.debug('{0} binary polar masks created with shape {1} and center {2}'.format(len(coords), shape, center))
        return res
    else:
        logging.debug('Integer polar mask created with shape {0} and center {1}. {2} ROIs added ({3} empty)'.format(shape, center, len(coords), len(coords)-np.max(res)))
        return res-1
    

def ROIAverage(image, ROImask, boolMask=False, weights=None, norm=None, masknans=False, dtype=float, evalFunc=None, evalParams={}, debug=False):
    """
    Calculate the average value of an image on a series of ROIs.

    Parameters
    ----------
    image        - 2D image or 3D ndarray with list of images
    ROImask      - if boolMask : list of 2D bool arrays same size as image
                   else : 2D int array with same size as image, with each pixel labeled with the index of the
                          ROI it belongs to (0 based). Each pixel can only belong to one ROI.
                          Pixels not belonging to any ROI must be labeled with -1
    weights      - can do a weighted average instead of a simple average if this keyword parameter
                   is set.  weights.shape must = image.shape.
    norm         - Normalization factors. Equals the number of pixel belonging to each ROI if average is not weighted
                   If None (default), it is computed from ROImask
    masknans     - assume the presence of NaNs in the array: mask them and don't count them in
                   the normalization by setting their weight to zero. Set it to False if you are
                   sure that there are no NaNs to improve calculation speed
    dtype        - Datatype of the accumulator in which the elements are summed. 
                   If the accumulator is too small, np.sum generates overflow
    evalFunc     - if None, simple average will be computed.
                   Otherwise, what will be averaged will be a function of the pixel values 
                   ex: to compute the variance, use SquareDistFromMean()
    evalParams   - eventually specify additional parameters for evalFunc

    Returns
    -------
    ROI_avg   : if image is 2D: 1D float array with ROI-averaged data
                if image is 3D: 2D float array, one image per row, one ROI per column.
                If a bin contains NO DATA, it will have a NAN value because of the
                divide-by-sum-of-weights component.
    norm      : sum of weights within the ROI. If weights==None, this reduces to the number of pixels in the ROI
    """
    
    if image.shape[0]==0:
        return None, None
    
    if boolMask:
        nbins = len(ROImask)
        ROIboolMask = ROImask
    else:
        nbins = np.max(ROImask)+1
        ROIboolMask = [ROImask==b for b in range(nbins)]
        
    use_weights = (weights is not None or masknans)
    if weights is None and use_weights:
        if (image.ndim > 2):
            weights = np.ones_like(image[0])
        else:
            weights = np.ones_like(image)
    if masknans:
        weights = np.multiply(weights, ~np.isnan(image))
    if use_weights:
        use_img = np.multiply(image, weights)
        if norm is None:
            # normalization factor for each bin
            if (weights.ndim > 2):
                norm = np.array([[np.sum(np.multiply(weights[i], ROIboolMask[b])) for b in range(nbins)] for i in range(weights.shape[0])])
            else:
                norm = np.array([np.sum(np.multiply(weights, ROIboolMask[b])) for b in range(nbins)])
                if (use_img.ndim > 2):
                    norm = [norm] * use_img.shape[0]
    else:
        use_img = image
        if norm is None:
            norm = np.array([np.sum(ROIboolMask[b]) for b in range(nbins)])
            if (use_img.ndim > 2):
                norm = [norm] * use_img.shape[0]
        
    if debug:
        logging.debug('  ROIAverage function called with {0}D input of shape {1}'.format(use_img.ndim, use_img.shape))
        logging.debug('  Normalization has shape {0}, factors range from {1} to {2}'.format(norm.shape, np.min(norm), np.max(norm)))
        if use_weights:
            if weights is None:
                logging.warn('  WARNING: use_weights is True but weights is None!')
            else:
                logging.debug('  Weight image. Weights has shape {0} and range from {1} to {2}'.format(weights.shape, np.min(weights), np.max(weights)))
            strprint = '  Weighted image'
        else:
            strprint = '  No weighting. Original image'
        logging.debug(strprint + ' has shape {0} and ranges from {1} to {2}'.format(use_img.shape, np.min(use_img), np.max(use_img)))
    
    if (use_img.ndim > 2):
        if evalFunc==None:
            ROI_avg = np.array([[np.true_divide(np.sum(np.multiply(use_img[i], ROIboolMask[b]), dtype=dtype), norm[i][b]) 
                                 for b in range(nbins)] for i in range(use_img.shape[0])])
        else:
            ROI_avg = np.array([[np.true_divide(np.sum(np.multiply(evalFunc(use_img[i], **evalParams), ROIboolMask[b]), dtype=dtype), norm[i][b]) 
                                 for b in range(nbins)] for i in range(use_img.shape[0])])
    else:
        if evalFunc==None:
            ROI_avg = np.array([np.true_divide(np.sum(np.multiply(use_img, ROIboolMask[b]), dtype=dtype), norm[b]) for b in range(nbins)])
        else:
            ROI_avg = np.array([np.true_divide(np.sum(np.multiply(evalFunc(use_img, **evalParams), ROIboolMask[b]), dtype=dtype), 
                                                norm[b]) for b in range(nbins)])
    
    return ROI_avg, norm

def ROIEval(image, ROImask, evalFuncs, evalParams={}):
    """
    Evaluate a function or a list of functions on image values restricted to ROIs.

    Parameters
    ----------
    image        - The 2D image
    ROImask      - 2D int array with same size as image, with each pixel labeled with the index of the
                   ROI it belongs to (0 based). Each pixel can only belong to one ROI.
                   Pixels not belonging to any ROI must be labeled with -1
    evalFuncs    - Function or list of functions to be evaluated. First argument should be array-like (it will be pixel values)
                   return value can be anything (does not need to be numeric)
    evalParams   - Dict or list of dicts, eventually specify additional parameters for evalFunc

    Returns
    -------
    ROIres   :  if single function is given: list of results, one item per ROI
                if multiple functions : list of lists of results
                                        ROIres[i][j] will be evaluation of i-th function on j-th ROI
    """
    if sf.IsIterable(evalFuncs):
        flatten_res = False
    else:
        evalFuncs = [evalFuncs]
        flatten_res = True
    evalParams = sf.CheckIterableVariable(evalParams, len(evalFuncs), force_length=True)
    ROIres = [[f(image[ROImask==b], **evalParams[i]) for b in range(np.max(ROImask))] for i, f in enumerate(evalFuncs)]
    if flatten_res:
        return ROIres[0]
    else:
        return ROIres
    


def PolarMaskCoords(r_list, a_list=None, flatten_res=True):
    """Generate a list of polar masks coordinates, each mask of the form [r, a, dr, da]
    
    Parameters
    ----------
    r_list    : list of radii (in pixel units) or list of couples [r_min, r_max]
    a_list    : list of angles (in radians) or list of couples [a_min, a_max]. 
                Zero angle corresponds with the +x axis direction
                None corresponds to [0, 2*np.pi]
    flatten_res: if True, flatten the (r, a) dimensions into a single list.
                otherwise, return a 3D array with separate r and a axes
    
    Returns
    -------
    mSpecs: 2D or 3D array, depending on flatten_res. Last dimension is [r, a, dr, da]
    """
    if a_list is None:
        a_list = [0, 2*np.pi]
    if (not sf.IsIterable(r_list[0])):
        tmp_list = []
        for i in range(len(r_list)-1):
            tmp_list.append([r_list[i], r_list[i+1]])
        r_list = tmp_list
    if (not sf.IsIterable(a_list[0])):
        tmp_list = []
        for i in range(len(a_list)-1):
            tmp_list.append([a_list[i], a_list[i+1]])
        a_list = tmp_list
    mSpecs = np.empty((len(r_list), len(a_list), 4), dtype=float)
    for r_idx in range(len(r_list)):
        for a_idx in range(len(a_list)):
            #print('{0} ; {1} ; {2} ; {3}'.format(r_idx, a_idx, r_list[r_idx], a_list[a_idx]))
            mSpecs[r_idx, a_idx] = [0.5*(r_list[r_idx][0] + r_list[r_idx][1]),\
                                    0.5*(a_list[a_idx][0] + a_list[a_idx][1]),\
                                    r_list[r_idx][1] - r_list[r_idx][0],\
                                    a_list[a_idx][1] - a_list[a_idx][0]]
    logging.debug('PolarMaskCoords created with\n\t- {0} radial annuli from {1:.2f} (+- {2:.2f}) px to {3:.2f} (+- {4:.2f}) px '.format(len(r_list), mSpecs[0,0,0], 0.5*mSpecs[0,0,2], mSpecs[-1,0,0], 0.5*mSpecs[-1,0,2]) +
                  'and\n\t- {0} azimuthal sectors from {1} (+- {2:.2f}) rad to {3:.2f} (+- {4:.2f}) rad'.format(len(a_list), mSpecs[0,0,1], 0.5*mSpecs[0,0,3], mSpecs[0,-1,1], 0.5*mSpecs[0,-1,3]))
    if flatten_res:
        return mSpecs.reshape(-1, mSpecs.shape[-1])
    else:
        return mSpecs
    
    
def LoadImageTimes(img_times_source, root_folder=None, usecols=0, skiprows=1, default_value=None, squeeze_res=False):
    '''
    Load image times from file or list of files
    '''
    if img_times_source is not None:
        if usecols is None:
            max_col = 0
        elif np.isscalar(usecols):
            max_col = usecols
        else:
            max_col = np.max(usecols)
        # if img_times_source is a string, let's use a single text file as input.
        # otherwise, it can be a list: in that case, let's open each text file and append all results
        if (isinstance(img_times_source, str)):
            fpath = os.path.join(root_folder, img_times_source)
            if sf.CountFileColumns(fpath, firstlineonly=False) > max_col:
                res = np.loadtxt(fpath, dtype=float, usecols=usecols, skiprows=skiprows, ndmin=2)
            else:
                res = default_value
                logging.warning('DSH.SALS.LoadImageTimes(): file ' + str(fpath) + ' incompatible with usecols ' + str(usecols) + '. Returning default value ' + str(res))
        else:
            res = np.empty(shape=(0,), dtype=float)
            for cur_f in img_times_source:
                fpath = os.path.join(root_folder, cur_f)
                if sf.CountFileColumns(fpath, firstlineonly=False) > max_col:
                    res = np.append(res, np.loadtxt(fpath, dtype=float, usecols=usecols, skiprows=skiprows, ndmin=2))
                else:
                    logging.warning('DSH.SALS.LoadImageTimes(): file ' + str(fpath) + ' incompatible with usecols ' + str(usecols) + '. Skipping file from list')
            if len(res)<=0:
                res = default_value
                logging.warning('DSH.SALS.LoadImageTimes(): no ok file in list ' + str(img_times_source) + ' returning default value ' + str(res))
    else:
        default_value
        logging.debug('DSH.SALS.LoadImageTimes(): no file specified. Returning default value ' + str(res))
    if squeeze_res:
        res = np.squeeze(res)
    return res

def FindTimelags(times, lags, subset_len=None):
    '''
    Find lagtimes given a list of time points and a list of lag indexes
    
    Parameters
    ----------
    times:          list of time points (float), not necessarily equally spaced
    lags:           list of lag indexes (int, >=0)
    subset_len:     int (>0) or None. Eventually divide the analysis in sections of subset_len datapoints each
                    If None, it will be set to the total number of datapoints (it will analyze the whole section)
                
    Returns
    -------
    allags:         2D list. allags[i][j] = time[j+lag[i]] - time[j]
                    NOTE: len(allags[i]) depends on i (no element is added to the list if j+lag[i] >= len(times))
    unique_laglist: 2D list. Element [i][j] is j-th lagtime of i-th analyzed subsection
    '''
    if subset_len is None:
        subset_len = len(times)
    logging.debug('FindTimelags: now finding lagtimes in time series (' + str(len(times)) + 
                  ' time points, divided into sections of ' + str(subset_len) + ' datapoints each) with ' + 
                  str(len(lags)) + ' lag indexes: ' + str(lags))
    alllags = []
    for lidx in range(len(lags)):
        if (lags[lidx]==0):
            alllags.append(np.zeros_like(times, dtype=float))
        elif (lags[lidx] < len(times)):
            alllags.append(np.subtract(times[lags[lidx]:], times[:-lags[lidx]]))
        else:
            alllags.append([])
    logging.debug('alllags list has {0} elements, with lengths ranging from {1} to {2}'.format(len(alllags), len(alllags[0]), len(alllags[-1])))
    unique_laglist = []
    for tavgidx in range(int(math.ceil(len(times)*1./subset_len))):
        cur_uniquelist = np.unique([alllags[i][j] for i in range(len(lags)) 
                                    for j in range(tavgidx*subset_len, min((tavgidx+1)*subset_len, len(alllags[i])))])
        cur_coarsenedlist = [cur_uniquelist[0]]
        for lidx in range(1, len(cur_uniquelist)):
            if not sf.IsWithinTolerance(cur_uniquelist[lidx], cur_coarsenedlist[-1], 
                                          tolerance=SALS_DT_TOLERANCE, tolerance_isrelative=SALS_DT_TOLERANCE_ISREL):
                cur_coarsenedlist.append(cur_uniquelist[lidx])
        unique_laglist.append(cur_coarsenedlist)
    logging.debug('unique_laglist has {0} elements. First line has {1} elements, ranging from {2} to {3}'.format(len(unique_laglist), len(unique_laglist[0]), unique_laglist[0][0], unique_laglist[0][-1]))
    return alllags, unique_laglist
    
def AverageG2M1(cI_file, average_T=None, save_fname=None):
    cur_cI, cur_times, cur_lagidx_list, roi_idx, exp_idx = ReadCIfile(cI_file)
    
    g2m1, g2m1_lags = AverageCorrTimetrace(cur_cI, cur_times, cur_lagidx_list, average_T)
    
    str_hdr_g = str(TXT_DELIMITER).join(['dt'+TXT_DELIMITER+'t{0:.2f}'.format(cur_times[tavgidx*average_T]) for tavgidx in range(g2m1.shape[0])])
    g2m1_out = np.empty((g2m1.shape[1], 2*g2m1.shape[0]), dtype=float)
    g2m1_out[:,0::2] = g2m1_lags.T
    g2m1_out[:,1::2] = g2m1.T
    
    if save_fname is None:
        save_fname = G2M1_PREFIX + sf.GetFilenameFromCompletePath(cI_file)[len(CI_PREFIX):]
    
    np.savetxt(os.path.join(os.path.dirname(cI_file), save_fname), 
           g2m1_out, header=str_hdr_g, delimiter=TXT_DELIMITER, comments=TXT_COMMENT)

def AverageCorrTimetrace(CorrData, ImageTimes, Lagtimes_idxlist, average_T=None):
    '''
    Average correlation timetraces
    
    Parameters
    ----------
    - CorrData: 2D array. Element [i,j] is correlation between t[i] and t[i]+tau[j]
    - ImageTimes: 1D array, float. i-th element is the physical time at which i-th image was taken
    - Lagtimes_idxlist: 1D array, int. i-th element is the lagtime, in image units
    - average_T: int or None. When averaging over time, resolve the average on chunks of average_T images each
                 if None, result will be average on the whole stack
    
    Returns
    -------
    - g2m1: 2D array. Element [i,j] represents j-th lag time and i-th time-resolved chunk
    - g2m1_lags: 2D array. It contains the time delays, in physical units, of the respective correlation data
    '''
    
    if average_T is None:
        tavg_num = 1
        average_T = CorrData.shape[0] 
    else:
        tavg_num = int(math.ceil(CorrData.shape[0]*1.0/average_T))
            
    g2m1_alllags, g2m1_laglist = FindTimelags(times=ImageTimes, lags=Lagtimes_idxlist, subset_len=average_T)
    g2m1 = np.zeros((tavg_num, np.max([len(l) for l in g2m1_laglist])), dtype=float)
    g2m1_lags = np.nan * np.ones_like(g2m1, dtype=float)
    g2m1_avgnum = np.zeros_like(g2m1, dtype=int)
    logging.debug('AverageCorrTimetrace: cI time averages will be performed by dividing the {0} time points into {1} windows of {2} time points each'.format(CorrData.shape[0], tavg_num, average_T))
    logging.debug('original cI has shape ' + str(CorrData.shape) + '. Averaged g2m1 has shape ' + str(g2m1.shape) + ' (check: ' + str(g2m1_avgnum.shape) + ')')
    
    for tidx in range(CorrData.shape[0]):
        cur_tavg_idx = tidx // average_T
        if (cur_tavg_idx >= g2m1_lags.shape[0]):
            logging.warn('AverageCorrTimetrace: {0}-th time point should go to {1}-th subsection, but result has only {2} subsections'.format(tidx, cur_tavg_idx, g2m1_lags.shape[0]))
        g2m1_lags[cur_tavg_idx,:len(g2m1_laglist[cur_tavg_idx])] = g2m1_laglist[cur_tavg_idx]
        for lidx in range(CorrData.shape[1]):
            if (tidx < len(g2m1_alllags[lidx])):
                cur_lagidx = np.argmin(np.abs(np.subtract(g2m1_laglist[cur_tavg_idx], g2m1_alllags[lidx][tidx])))
                if (~np.isnan(CorrData[tidx,lidx])):
                    g2m1_avgnum[cur_tavg_idx,cur_lagidx] += 1
                    g2m1[cur_tavg_idx,cur_lagidx] += CorrData[tidx,lidx]
    g2m1 = np.divide(g2m1, g2m1_avgnum)
    
    return g2m1, g2m1_lags









class ROIproc():
    """ Class to process MIfile computing averages and time correlations on Regions Of Interest (ROIs) """
    
        def __init__(self, MIin, ROIs, maskRaw=None, imgTimes=None, expTimes=[1]):
        """
        Initialize SALS

        Parameters
        ----------
        MIin : input MIfile or MIstack. It can be empty (i.e. initialized with metadata only)
        ROIs :      integer mask with ROI indexes for every pixel, 0-based.
                    Each pixel can only belong to no more than one ROI.
                    Pixels belonging to no ROI are labeled with -1
                    Number of ROI is given by np.max(mask)
                    None corresponds to setting every pixel to zero
        maskRaw :   2D binary array with same shape as MIin.ImageShape()
                    True values (nonzero) denote pixels that will be included in the analysis,
                    False values (zeroes) will be excluded
                    If None, all pixels will be included.
                    Disregarded if ROIs is already a raw mask
        imgTimes :  Float array of length Nimgs. i-th element will be the time of the image.
                    If none, images will be 
        """
        
        self.MIinput   = MIin
        self.SetROIs(ROIs, maskRaw=maskRaw)
        self._loadTimes(imgTimes)
        self.SetExptimes(expTimes)
        self._initConstants()
        
    def _initConstants(self):
        #Constants
        self.HistogramSLS = False
        self.MaxSafeAvgIntensity = 40
        self.dt_tolerance = 1e-2
        self.dt_tolerance_isrelative = True
        self.DebugMode = False
        self.txt_delim = '\t'
        self.txt_comm = '#'
        self.savetxt_kwargs = {'delimiter': self.txt_delim, 'comments': self.txt_comm}
        
    def __repr__(self):
        if (self.MIinput.IsStack()):
            return '<ROIproc object: MIstack >> ' + str(self.outFolder) + '>'
        else:
            return '<ROIproc object: MIfile (' + str(self.MIinput.FileName) + ') >> ' + str(self.outFolder) + '>'

    def __str__(self):
        str_res  = '\n|-----------------|'
        str_res += '\n|  ROIproc class: |'
        str_res += '\n|-----------------+---------------'
        str_res += '\n| Input           : '
        if (self.MIinput.IsStack()):
            str_res += 'MIstack (' + self.MIinput.Count() + ' MIfiles)'
        else:
            str_res += 'MIfile (' + self.MIinput.FileName + ')'
        str_res += ', ' + str(self.MIinput.ImageNumber()) + ' images'
        str_res += '\n| ROIs            : ' + str(self.CountROIs()) + ' (' + str(self.CountValidROIs()) + ' valid, ' + str(self.CountEmptyROIs()) + ' empty)'
        str_res += '\n| Exposure times  : ' + str(self.NumExpTimes()) + ', from ' + str(self.expTimes[0]) + ' to ' + str(self.expTimes[-1])
        str_res += '\n|-----------------+---------------'
        return str_res
    
    def SetROIs(self, ROIs, maskRaw=None):
        '''
        Sets ROIs
        
        Parameters
        ----------
        ROI_specs : integer mask with ROI indexes for every pixel, 0-based.
                    Each pixel can only belong to no more than one ROI.
                    Pixels belonging to no ROI are labeled with -1
                    Number of ROI is given by np.max(mask)
        maskRaw :   2D binary array with same shape as MIin.ImageShape()
                    True values (nonzero) denote pixels that will be included in the analysis,
                    False values (zeroes) will be excluded
                    If None, all pixels will be included.
                    Disregarded if ROIs is already a raw mask

        '''
        if maskRaw is None:
            self.ROIs = ROIs
        else:
            self.ROIs = np.where(maskRaw==0, -1, ROIs)

        self.ROI_masks = [self.ROIs==b for b in range(self.CountROIs())]
        self.ROI_maskSizes = np.array([np.sum(self.ROI_masks[b]) for b in range(self.CountROIs())])
        if self.CountEmptyROIs() > 0:
            if self.CountValidROIs() > 0:
                logging.warning('There are {0} out of {1} empty masks'.format(self.CountEmptyROIs(), self.CountROIs()))
            else:
                logging.error('ROI mask is empty (no valid ROIs found)')
        else:
            logging.info('Set {0} valid ROIs'.format(self.CountROIs()))
            
    def SetExptimes(self, expTimes):
        if len(expTimes) > 0:
            _exps = np.unique(expTimes)
            # check that expTimes is sorted:
            #assert np.all(np.diff(expTimes) >= 0), 'Exposure times ' + str(expTimes) + ' must be sorted!'
            self.expTimes = np.asarray(sorted(_exps))
            if len(self.expTimes) > 1:
                logging.debug('Set {0} exptimes, sorted from {1} to {2}'.format(len(self.expTimes), self.expTimes[0], self.expTimes[-1]))
            else:
                logging.debug('Set one single exposure time: {0}'.format(self.expTimes[0]))
        else:
            logging.error('ROIproc.SetExptimes() called with empty expTimes list: ' + str(expTimes))

    def CountROIs(self):
        return np.max(self.ROIs)+1
    def ImageNumber(self):
        return self.MIinput.ImageNumber()
    def NumTimes(self):
        return self.MIinput.ImageNumber() // len(self.expTimes)
    def NumExpTimes(self):
        return len(self.expTimes)
    def StackInput(self):
        return self.MIinput.IsStack()

    def SaveIavg(self, SaveFolder, Iavg, NormF, AllExpData=None):
        """ Saves output of SLS analysis

        Parameters
        ----------
        IofR : 2D array of shape (NumTimes(), NumROIs())
        NormF : 1D array with ROI normalization factors
        AllExpData : None or [I, exptime], data with all exposure times
        """
        roi_norms = np.zeros((Iavg.shape[-1], 1))
        roi_norms[:len(NormF),0] = NormF
        MI.WriteBinary(os.path.join(SaveFolder, 'ROI_mask.raw'), self.ROIs, 'i')
        
        str_hdr_avg = 'r[px]'+self.txt_delim+'phi[rad]' + 
                        ''.join([self.txt_delim+'t{0:.2f}'.format(self.imgTimes[i]) for i in range(0, self.ImageNumber(), self.NumExpTimes())])
        np.savetxt(os.path.join(SaveFolder, 'Iavg.dat'), np.append(self.ROIcoords[:IofR.shape[1],:2], Iavg.T, axis=1), 
                   header=str_hdr_avg, **self.savetxt_kwargs)
        if AllExpData is not None:
            ROIavgs_allExp, BestExptime_Idx = AllExpData
            np.savetxt(os.path.join(SaveFolder, 'exptimes.dat'), np.append(self.ROIcoords[:,:2], BestExptime_Idx.T, axis=1), 
                       header=str_hdr_avg, **self.savetxt_kwargs)
            str_hdr_raw = 'r[px]'+self.txt_delim+'phi[rad]' + ''.join([self.txt_delim+'t{0:.2f}_e{1:.3f}'.format(self.imgTimes[i], self.expTimes[i%len(self.expTimes)]) 
                                                                      for i in range(len(self.imgTimes))])
            np.savetxt(os.path.join(SaveFolder, 'Iavg_raw.dat'), np.append(self.ROIcoords[:,:2], ROIavgs_allExp.reshape((-1, ROIavgs_allExp.shape[-1])).T, axis=1), 
                       header=str_hdr_raw, **self.savetxt_kwargs)

    def LoadIavg(self, outFolder):
        Ir_allexp, Ir, best_exptimes = None, None, None
        Iavg_fpath = os.path.join(outFolder, 'Iavg.dat')
        if os.path.isfile(Iavg_fpath):
            Iavg = np.loadtxt(Iavg_fpath, **self.savetxt_kwargs)
            if (Iavg.shape[1] > 2):
                Iavg = Iavg[:,2:].T
                logging.debug('Loading average intensity data from {0}: output has shape {1}'.format(Iavg_fpath, Iavg.shape))
            else:
                Iavg = None
                logging.warn('Loading average intensity data from {0} failed: None returned'.format(Iavg_fpath))
        if Iavg is not None:
            Iavraw_fpath = os.path.join(outFolder, 'Iavg_raw.dat')
            if os.path.isfile(Iavraw_fpath):
                Iav_allexp = np.loadtxt(Iavraw_fpath, **self.savetxt_kwargs)
                if (Iav_allexp.shape[1] > 2):
                    Iav_allexp = Iav_allexp[:,2:].T
                    Iav_allexp = np.expand_dims(Iav_allexp, axis=1)
                    logging.debug('Loading raw average intensity data from {0}: output has shape {1}'.format(Iavraw_fpath, Iav_allexp.shape))
                else:
                    Iav_allexp = None
                    logging.warn('Loading raw average intensity data from {0} failed: None returned'.format(Iavraw_fpath))
        Iexp_fpath = os.path.join(outFolder, 'exptimes.dat')
        if os.path.isfile(Iexp_fpath):
            best_exptimes = np.loadtxt(Iexp_fpath, **self.savetxt_kwargs)
            if (best_exptimes.shape[1] > 2):
                best_exptimes = best_exptimes[:,2:].T
                logging.debug('Loading best exposure times from {0}: output has shape {1}'.format(Iexp_fpath, best_exptimes.shape))
            else:
                best_exptimes = None
                logging.warn('Loading best exposure times from {0} failed: None returned'.format(Iexp_fpath))
                
        return Iav_allexp, Iavg, best_exptimes

    def ReadCIfile(self, fpath):
        return iof.ReadCIfile(fpath)

    def AverageG2M1(self, outFolder, averageT=None, cI_prefix='cI_', save_prefix='g2m1_'):
        if averageT is None:
            averageT = self.NumTimes()
        cI_fnames = sf.FindFileNames(outFolder, Prefix=cI_prefix, Ext='.dat')
        
        for cur_f in cI_fnames:
            AverageG2M1(os.path.join(outFolder, cur_f), average_T=averageT, save_fname=save_prefix+cur_f[len(cI_prefix):])
    
    def GetOrReadImage(self, img_idx, buffer=None):
        """ Retrieve image from buffer if present, otherwise read if from MIfile
        """
        if buffer is not None:
            if len(buffer) > img_idx:
                return buffer[img_idx]
        return self.MIinput.GetImage(img_idx)
    
    def ROIaverageIntensity(self, stack1, no_buffer=False, imgs=None):
        return self.ROIaverageProduct(stack1, stack2=None, no_buffer=no_buffer, imgs=imgs)
    
    def ROIaverageProduct(self, stack1, stack2=None, no_buffer=False, imgs=None):
        """ ROI average product of images

        Parameters
        ----------
        stack1 : list of indexes. Images will be either read by MIinput or retrieved from img_buffer
        stack2 : None, or list of indexes
                 - if None: function will return averages of single images (in stack1)
                 - if list: length should be the same as stack1
        no_buffer : if True, avoid reading all images to a buffer, but read images one by one
                    (dumping them afterwards)
        imgs : None or 3D array with buffered images. If None, images will be read from MIinput

        Returns
        -------
        AvgRes : 2D array. Element [i,j] is the average of i-th image on j-th ROI
        NormList : 1D array. i-th element is the number of pixels in i-th ROI.
        """
        num_ROI = self.CountROIs()
            
        if (self.StackInput() or no_buffer):
            AvgRes = np.nan*np.ones((len(stack1), num_ROI), dtype=float)
            for i in range(AvgRes.shape[0]):
                if stack2 is None:
                    AvgRes[i], NormList = ROIAverage(self.GetOrReadImage(stack1[i], imgs), ROIboolMask, boolMask=True, norm=MaskSize)
                else:
                    if (stack1[i]==stack2[i]):
                        AvgRes[i], NormList = ROIAverage(np.square(self.GetOrReadImage(stack1[i], imgs)), ROIboolMask, boolMask=True, norm=MaskSize)
                    else:
                        AvgRes[i], NormList = ROIAverage(np.multiply(self.GetOrReadImage(stack1[i], imgs), self.GetOrReadImage(stack2[i], imgs)), ROIboolMask, boolMask=True, norm=MaskSize)
                    if (self.DebugMode):
                        if (np.any(AvgRes[i]<0)):
                            min_idx = np.argmin(AvgRes[i])
                            logging.warn('Negative cross product value (image1: {0}, image2: {1}, ROI{2} avg: {3})'.format(stack1[i], stack2[i], min_idx, AvgRes[i][min_idx]))
                            logging.debug('   >>> Debug output for ROIAverage function:\n'
                                          + str(ROIAverage(np.multiply(self.GetOrReadImage(stack1[i], imgs), self.GetOrReadImage(stack2[i], imgs)), ROIboolMask, boolMask=True, norm=MaskSize, debug=True)))
        else:
            if imgs is None:
                imgs = self.MIinput.Read()
            if stack2 is None:
                cur_stack = imgs[stack1]
            elif np.array_equal(stack1, stack2):
                cur_stack = np.square(imgs[stack1])
            else:
                cur_stack = np.multiply(imgs[stack1], imgs[stack2])
            AvgRes, NormList = ROIAverage(cur_stack, ROIboolMask, boolMask=True, norm=MaskSize)
            NormList = NormList[0]
            
        return AvgRes, NormList
    
    def CorrelateWithImage(self, ref_idx=[0], no_buffer=False):
        """ Compute correlations between a given (list of) reference image(s) and all other images
        """

        ROIavgs_allExp, ROIavgs_best, BestExptime_Idx, buf_images = self.doSLS(ROImasks=ROI_boolMasks, saveFolder=self.outFolder, buf_images=None, 
                                                                               no_buffer=no_buffer, force_calc=force_SLS)
        if buf_images is None:
            if no_buffer:
                self.MIinput.OpenForReading()
                buf_images = None
            elif self.StackInput()==False:
                buf_images = self.MIinput.Read()
                

    def doSLS(self, saveFolder, buf_images=None, no_buffer=False, force_calc=True):
        """ Run SLS analysis
        
        Parameters
        ----------
        - ROImasks: list of binary masks, one element per ROI. 
                    Each (i-th) element is a binary image, pixel is 1 if it belongs to i-th ROI, else it is 0 
                    if None, they will be computed from self.ROIs
        - saveFolder: folder path, 'auto' or None. If not None, save analysis output in specified folder. 
                      If 'auto', the standard output folder for SALS analysis will be used
        - buf_images: 3D array, buffer with images to be processed. If None, images will be loaded
        - no_buffer: bool, used only if buf_images is None. If False, the entire image stack will be read in a buffer at once.
                     otherwise, images will be loaded one by one
        - force_calc: bool. If False, program will search for previously computed SLS results and load those.
        
        Returns
        -------
        - ROIavgs_allExp : 3D array. Element [i,j,k] is the average of j-th exposure time in i-th exposure time sweep, averaged on k-th ROI
        - ROIavgs_best : 2D array. Element [i,j] is the best average intensity taken from i-th exposure time sweep, averaged on j-th ROI
        - BestExptime_Idx : 2D array (int). Element [i,j] is the index of the optimum exposure time for j-th ROI
        - buf_images : 3D array. Buffer of images eventually read during the analysis
        """
        
        ROI_boolMasks = [self.ROIs==b for b in range(self.CountROIs())]
        sf.CheckCreateFolder(saveFolder)
        
        ROIavgs_allExp, ROIavgs_best, BestExptime_Idx = None, None, None
        if not force_calc:
            ROIavgs_allExp, ROIavgs_best, BestExptime_Idx = self.LoadSLS()
        
        if ROIavgs_allExp is None or ROIavgs_best is None or BestExptime_Idx is None:

            if buf_images is None:
                if no_buffer:
                    self.MIinput.OpenForReading()
                    buf_images = None
                elif self.StackInput()==False:
                    buf_images = self.MIinput.Read()

            if ROImasks is None:
                ROImasks = [self.ROIs==b for b in range(self.CountROIs())]

            # Compute average intensity for all images
            all_avg, NormList = self.ROIaverageProduct(stack1=list(range(self.ImageNumber())), stack2=None, ROImasks=ROImasks, 
                                                       masks_isBool=True, no_buffer=no_buffer, imgs=buf_images)
            if all_avg.shape[0] % (self.NumTimes() * self.NumExpTimes()) != 0:
                limit_len = self.NumTimes() * self.NumExpTimes()
                all_avg = all_avg[:limit_len]
                logging.warning('Number of images ({0}) is not a multiple of exposure times ({1}). '.format(self.ImageNumber(), self.NumExpTimes()) + 
                                'Average intensity output of shape {0} cannot be reshaped using number of times ({1}) and exposure times ({2}). '.format(all_avg.shape, self.NumTimes(), self.NumExpTimes()) +
                                'Restricting SLS analysis to first {0} images'.format(limit_len))
            ROIavgs_allExp = all_avg.reshape((self.NumTimes(), self.NumExpTimes(), -1))
            ROIavgs_best, BestExptime_Idx = self.FindBestExptimes(ROIavgs_allExp)
            if saveFolder is not None:
                self.SaveSLS(ROIavgs_best, NormList, [ROIavgs_allExp, BestExptime_Idx], save_folder=saveFolder)
            logging.debug('SLS output saved')

            # TODO: time average SLS
        
        strlog = 'SLS analysis returned: raw data (shape: {0}), I(r) data (shape: {1}), exptime data (shape: {2})'.format(ROIavgs_allExp.shape, ROIavgs_best.shape, BestExptime_Idx.shape)
        if buf_images is None:
            strlog += ', no buffer images'
        else:
            strlog += ', buffer images (shape {0})'.format(buf_images.shape)
        logging.debug(strlog)
        
        return ROIavgs_allExp, ROIavgs_best, BestExptime_Idx, buf_images
